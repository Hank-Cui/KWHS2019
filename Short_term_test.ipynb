{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hank-Cui/otis2019/blob/master/Short_term_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwRY2Ddil66I",
        "colab_type": "code",
        "outputId": "a1646c5b-5525-4255-be9d-da271293f5d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from pandas.plotting import autocorrelation_plot\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "%pip install --upgrade xgboost\n",
        "import xgboost as xgb\n",
        "\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "import PIL\n",
        "import imageio\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.17.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0Y-Oou5mANI",
        "colab_type": "code",
        "outputId": "b83d41f4-f48c-4f34-b8f7-822d71ea9072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXqsoSNEmK8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu1ZDgfPnNKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_list = glob.glob(\"/gdrive/My Drive/Blair/10/KWHS2019/hist_data/*\")\n",
        "df = pd.read_csv(\"/gdrive/My Drive/Blair/10/KWHS2019/KWHS_list.csv\")\n",
        "stock_list = df['TICKER']\n",
        "technology = df[df['SECTOR'] == \"Technology\"]\n",
        "energy = df[df['SECTOR'] == \"Energy\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov1K-DtIPVx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comp_tic = \"GOOG\"\n",
        "df = pd.read_csv(\"/gdrive/My Drive/Blair/10/KWHS2019/hist_data/\"+comp_tic+\".csv\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1QjJM63f8q-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_stock(company_name, days):\n",
        "    comp_tic = company_name\n",
        "\n",
        "    df = pd.read_csv(\"/gdrive/My Drive/Blair/10/KWHS2019/hist_data/\"+comp_tic+\".csv\")\n",
        "    df = df[-days:]\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df.Date,format='%Y-%m-%d')\n",
        "    df.index = df['Date']\n",
        "\n",
        "    #plot\n",
        "    df = tech_indictor(df)\n",
        "\n",
        "    plt.figure(figsize=(16,9), dpi=80)\n",
        "    plt.plot(df['Close'], label='Close Price history')\n",
        "    plt.plot(df['macd'], label='MACD', color='orange')\n",
        "    plt.plot(df['dea'], label='DEA', color='Magenta')\n",
        "    plt.plot(df['ma21'], label='MA 21', color='r', linestyle='--')\n",
        "    plt.plot(df['upper_band'], label='Upper Band', color='c')\n",
        "    plt.plot(df['lower_band'], label='Lower Band', color='c')\n",
        "    plt.plot(df['ma7'], label='MA 7', color='g',linestyle='--')\n",
        "\n",
        "\n",
        "    plt.title(comp_tic+' Stock Price') # 添加标题\n",
        "    plt.xlabel('Date') \n",
        "    plt.ylabel('USD')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtvK_oh_19eQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tech_indictor(data):\n",
        "\n",
        "    # Simple Moving Average\n",
        "    data['ma7'] = data['Close'].rolling(window=7).mean()\n",
        "    data['ma21'] = data['Close'].rolling(window=21).mean()\n",
        "\n",
        "    # MACD indicator\n",
        "    data['ema12'] = data.Close.ewm(span=12, adjust=False).mean()\n",
        "    data['ema26'] = data.Close.ewm(span=26, adjust=False).mean()\n",
        "    data['dea'] = data.Close.ewm(span=9, adjust=False).mean()\n",
        "    data['macd'] = data['ema12']-data['ema26']\n",
        "\n",
        "    # Bollinger Band\n",
        "    data['md'] = data.Close.rolling(window=20).std()\n",
        "    data['upper_band'] = data['ma21'] + (data['md'] * 2)\n",
        "    data['lower_band'] = data['ma21'] - (data['md'] * 2)\n",
        "\n",
        "    # Momentum\n",
        "    data['momentum'] = data['Close'] - 1\n",
        "\n",
        "    # Exponential Moving Average\n",
        "    data['ema'] = data['Close'].ewm(com=0.5).mean()\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAnBNBx7dXnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fundamental_analysis:\n",
        "  #TODO:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjQGry0MPz0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def show_fourier_transform(comp_tic, days):\n",
        "    df = pd.read_csv(\"/gdrive/My Drive/Blair/10/KWHS2019/hist_data/\"+comp_tic+\".csv\")\n",
        "    df = df[-days:]\n",
        "\n",
        "    data_FT = df[['Date', 'Close']]\n",
        "    fft_list = np.fft.fft(np.array(data_FT['Close']))\n",
        "\n",
        "    plt.figure(figsize=(14, 7), dpi=100)\n",
        "\n",
        "    for i in [3, 6, 9, 30]:\n",
        "        fft_a = np.copy(fft_list)\n",
        "        fft_a[i:-i] = 0\n",
        "        plt.plot(np.fft.ifft(fft_a), label = 'Fourier Transform of %i components' % i)\n",
        "\n",
        "    plt.plot(np.array(data_FT['Close']),  label='Real')\n",
        "    plt.xlabel('Days')\n",
        "    plt.ylabel('USD')\n",
        "    plt.title('{} close stock prices + Fourier transforms of recent {} days'.format(comp_tic, days))\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hrs9p-M3TuFB",
        "colab": {}
      },
      "source": [
        "def show_arima_predictions(comp_tic, days):\n",
        "\n",
        "    df_1 = pd.read_csv(\"/gdrive/My Drive/Blair/10/KWHS2019/hist_data/\"+comp_tic+\".csv\")\n",
        "    # df_1 = pd.read_csv(\"/content/AAPL.csv\")\n",
        "    data = np.array(df_1[-days:]['Close'])\n",
        "\n",
        "    model = ARIMA(data, order=(5, 1, 0))\n",
        "    model_fit = model.fit(disp=0)\n",
        "    print(model_fit.summary())\n",
        "    autocorrelation_plot(data)  \n",
        "    plt.figure(figsize=(10, 7), dpi=80)\n",
        "    plt.show() \n",
        "\n",
        "    train, test = train_test_split(data, test_size=0.33, shuffle=False)\n",
        "\n",
        "    history = [x for x in train]\n",
        "    predictions = []\n",
        "\n",
        "    # train data\n",
        "    for i in range(len(test)): \n",
        "        model = ARIMA(history, order=(5,1,0))\n",
        "        model_fit = model.fit(disp=0)\n",
        "        output = model_fit.forecast()\n",
        "        result = output[0]\n",
        "        predictions.append(result)\n",
        "        obs = test[i]\n",
        "        history.append(obs)\n",
        "\n",
        "    error = mean_squared_error(test, predictions) # calculate MSE\n",
        "    print('Test MSE: %.3f' % error)\n",
        "\n",
        "    plt.figure(figsize=(12, 6), dpi=100)\n",
        "    plt.plot(test, label='Real')\n",
        "    plt.plot(predictions, color='red', label='Predicted')\n",
        "    plt.xlabel('Days')\n",
        "    plt.ylabel('USD')\n",
        "    plt.title('ARIMA model on {} stock'.format(comp_tic))\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXIObGmuOT3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_Weight(comp_tic, days):\n",
        "    a = tech_indictor(df)[-days:]\n",
        "    b = df[['ma7','ma21','ema12', 'ema26', 'md', 'macd','upper_band','lower_band']][-days:]\n",
        "    data = b.copy()\n",
        "    \n",
        "    y = a['Close']\n",
        "    X = data\n",
        "\n",
        "    X_train_FI, X_test_FI, y_train_FI, y_test_FI = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
        "\n",
        "    regressor = xgb.XGBRegressor(gamma=0.0,\n",
        "                                n_estimators=1500,\n",
        "                                base_score=0.7,\n",
        "                                colsample_bytree=1,\n",
        "                                learning_rate=0.03)\n",
        "\n",
        "    xgbModel = regressor.fit(X_train_FI,y_train_FI, \\\n",
        "                            eval_set = [(X_train_FI, y_train_FI), (X_test_FI, y_test_FI)], \\\n",
        "                            verbose=False)\n",
        "\n",
        "    eval_result = regressor.evals_result()\n",
        "    training_rounds = range(len(eval_result['validation_0']['rmse']))\n",
        "\n",
        "    plt.scatter(x=training_rounds,y=eval_result['validation_0']['rmse'],label='Training Error')\n",
        "    plt.scatter(x=training_rounds,y=eval_result['validation_1']['rmse'],label='Validation Error')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.title('Training Vs Validation Error')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    plt.xticks(rotation='vertical')\n",
        "    plt.bar([i for i in range(len(xgbModel.feature_importances_))], xgbModel.feature_importances_.tolist(), tick_label=X_test_FI.columns)\n",
        "    plt.title('Figure 6: Feature importance of the technical indicators.')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2n-7bSOySVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NN\n",
        "#TODO:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqTRVDki0l_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PCA\n",
        "pca = PCA(n_components=.8)\n",
        "x_pca = StandardScaler().fit_transform(vae_added_df)\n",
        "principalComponents = pca.fit_transform(x_pca)\n",
        "print(principalComponents.n_components_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3mRAaQA-dwu",
        "colab_type": "code",
        "outputId": "548bef6a-be2f-4e86-e99b-be71da6c0d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "#neural network\n",
        "\n",
        "def gpu_exists():\n",
        "    try:\n",
        "        mx.nd.zeros((1,), ctx=mx.gpu(0))\n",
        "    except:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "data_ctx = mx.cpu()\n",
        "if gpu_exists():\n",
        "    print('Using GPU for model_ctx')\n",
        "    model_ctx = mx.gpu(0)\n",
        "else:\n",
        "    print('Using CPU for model_ctx')\n",
        "    model_ctx = mx.cpu()\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/AAPL.csv\")\n",
        "num_training_days = 365\n",
        "data = np.array(df[-1000:]['Close'])\n",
        "\n",
        "#------------------------------------这一段什么意思？？\n",
        "VAE_data = data\n",
        "batch_size = 64\n",
        "n_batches = VAE_data.shape[0]/batch_size\n",
        "VAE_data = VAE_data.values\n",
        "\n",
        "train_iter = mx.io.NDArrayIter(data={'data': VAE_data[:num_training_days,:-1]}, \\\n",
        "                               label={'label': VAE_data[:num_training_days, -1]}, batch_size = batch_size)\n",
        "test_iter = mx.io.NDArrayIter(data={'data': VAE_data[num_training_days:,:-1]}, \\\n",
        "                              label={'label': VAE_data[num_training_days:,-1]}, batch_size = batch_size)\n",
        "# #-----------------------------------\n",
        "\n",
        "model_ctx =  mx.gpu() #cpu()\n",
        "\n",
        "class VAE(gluon.HybridBlock):\n",
        "    def __init__(self, n_hidden=400, n_latent=2, n_layers=1, n_output=784, \\\n",
        "                 batch_size=100, act_type='relu', **kwargs):\n",
        "        self.soft_zero = 1e-10\n",
        "        self.n_latent = n_latent\n",
        "        self.batch_size = batch_size\n",
        "        self.output = None\n",
        "        self.mu = None\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        \n",
        "        with self.name_scope():\n",
        "            self.encoder = nn.HybridSequential(prefix='encoder')\n",
        "            \n",
        "            for i in range(n_layers):\n",
        "                self.encoder.add(nn.Dense(n_hidden, activation=act_type))\n",
        "            self.encoder.add(nn.Dense(n_latent*2, activation=None))\n",
        "\n",
        "            self.decoder = nn.HybridSequential(prefix='decoder')\n",
        "            for i in range(n_layers):\n",
        "                self.decoder.add(nn.Dense(n_hidden, activation=act_type))\n",
        "            self.decoder.add(nn.Dense(n_output, activation='sigmoid'))\n",
        "\n",
        "    def hybrid_forward(self, F, x):\n",
        "        h = self.encoder(x)\n",
        "        #print(h)\n",
        "        mu_lv = F.split(h, axis=1, num_outputs=2)\n",
        "        mu = mu_lv[0]\n",
        "        lv = mu_lv[1]\n",
        "        self.mu = mu\n",
        "\n",
        "        eps = F.random_normal(loc=0, scale=1, shape=(self.batch_size, self.n_latent), ctx=model_ctx)\n",
        "        z = mu + F.exp(0.5*lv)*eps\n",
        "        y = self.decoder(z)\n",
        "        self.output = y\n",
        "\n",
        "        KL = 0.5*F.sum(1+lv-mu*mu-F.exp(lv),axis=1)\n",
        "        logloss = F.sum(x*F.log(y+self.soft_zero)+ (1-x)*F.log(1-y+self.soft_zero), axis=1)\n",
        "        loss = -logloss-KL\n",
        "\n",
        "        return loss\n",
        "\n",
        "n_hidden=400 # neurons in each layer\n",
        "n_latent=2 \n",
        "n_layers=3 # num of dense layers in encoder and decoder respectively\n",
        "n_output=VAE_data.shape[1]-1 \n",
        "\n",
        "net = VAE(n_hidden=n_hidden, n_latent=n_latent, n_layers=n_layers, n_output=n_output, batch_size=batch_size, act_type='gelu')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7e16670c2481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mVAE_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrain_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDArrayIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVAE_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_training_days\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m                                \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVAE_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_training_days\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASnf88QQZtb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}