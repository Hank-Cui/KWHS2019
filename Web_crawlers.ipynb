{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "一些爬虫.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hank-Cui/otis2019/blob/crawler/%E4%B8%80%E4%BA%9B%E7%88%AC%E8%99%AB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU9ubOm7UKfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Install yfinance\n",
        "%pip install yfinance\n",
        "%pip install selenium"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twfcBpDoxmn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pandas_datareader import data\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRvscfxD3kLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN25Jvc2b9Gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Selenium Colab\n",
        "# 暂时不用了\n",
        "\n",
        "install chromium, its driver, and selenium:\n",
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "preferences = {\"download.default_directory\":\"/content\", \n",
        "               \"safebrowsing.enabled\":\"false\", \n",
        "               \"profile.default_content_settings.popups\": 0}\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_options.add_experimental_option(\"prefs\", preferences)\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "wd.get(\"https://www.google.com\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kowJFRJ-NtFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 获取页面HTML\n",
        "# 调试用\n",
        "\n",
        "def get_html(url):\n",
        "    wp = requests.get(url)\n",
        "    web_html = BeautifulSoup(wp.text, 'html.parser')\n",
        "    file = open('test.html', 'w')  # 创建并打开html文件\n",
        "    file.write(web_html.prettify())  # 写入美丽的汤prettify后的文字\n",
        "    file.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRPb2MG3Ubvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 用yfinace获取csv历史数据\n",
        "\n",
        "def get_hist_data(tickets_list):\n",
        "    for ticket in tickets_list:\n",
        "        company = yf.Ticker(ticket)\n",
        "        company.info  # get stock info\n",
        "        hist = company.history(period=\"max\")  # get historical market data\n",
        "        hist.to_csv(r'/content//' + ticket + \".csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeGqGaY4Uf0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 在这个里面填股票代码\n",
        "TICKETS = ['AAPL', 'GOOG']\n",
        "get_hist_data(TICKETS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvRBzfJ0ZA0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 一堆不太好用的东西\n",
        "\n",
        "# wd.get(\"https://finance.yahoo.com/quote/AAPL/history?period1=0&period2=1569297600&interval=1d&filter=history&frequency=1d\")\n",
        "# xpath = '''//*[@id=\"Col1-1-HistoricalDataTable-Proxy\"]/section/div[1]/div[2]/span[2]/a'''\n",
        "# wd.find_element_by_xpath(xpath).click()\n",
        "# elem = wd.find_element_by_tag_name(\"body\")\n",
        "\n",
        "# no_of_scrowdowns = 100\n",
        "\n",
        "# while no_of_scrowdowns:\n",
        "#     elem.send_keys(Keys.PAGE_DOWN)\n",
        "#     #time.sleep(0.1)\n",
        "#     no_of_scrowdowns-=1\n",
        "\n",
        "# df = pd.read_html(wd.page_source)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79ozC_NaaQfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wp = requests.get(\"http://vip.stock.finance.sina.com.cn/usstock/ustotal.php\")\n",
        "web_html = BeautifulSoup(wp.text, 'html.parser')\n",
        "\n",
        "soup = BeautifulSoup(str(web_html))\n",
        "urls = []\n",
        "\n",
        "for a in soup.find_all('a', href=True):\n",
        "    if \n",
        "    urls.append(a['href'])\n",
        "\n",
        "for i in range(len(urls)):\n",
        "    if len(urls[i]) == 58: urls[i] = urls[i][48:53]\n",
        "    elif len(urls[i]) == 57: urls[i] = urls[i][48:52]\n",
        "    elif len(urls[i]) == 56: urls[i] = urls[i][48:51]\n",
        "    elif len(urls[i]) == 55: urls[i] = urls[i][48:50]\n",
        "    elif len(urls[i]) == 54: urls[i] = urls[i][48:49]\n",
        "\n",
        "get_hist_data(urls[21:-13])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
