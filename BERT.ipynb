{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ6jEYQ5hrpS",
        "colab_type": "text"
      },
      "source": [
        "**BERT MODEL TRAINED USING A RNN NETWORK**\n",
        "\n",
        "Peter Lau - \n",
        "Nov 2019\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-TihwxXJ-gP",
        "colab_type": "code",
        "outputId": "6c824062-9a92-4856-d677-e4b44b08c3f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wO9JUZxFB4w",
        "colab_type": "code",
        "outputId": "43fdba9f-3635-42f4-c9c9-8c43a33d3cde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pip install torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TefhFPqqcpgR",
        "colab_type": "text"
      },
      "source": [
        "Setting Up the Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARTHn-QyIAKE",
        "colab_type": "code",
        "outputId": "7285e6ff-7363-4958-f27b-ecf80f057769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.83)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.36)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.36 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.36)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->transformers) (2.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGyYuPhDHiar",
        "colab_type": "code",
        "outputId": "3c85fde3-7e7a-45bd-f633-1ba63f51f628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optimizer\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torchtext import datasets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgbCFLBnoO6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9btb8nfMfk2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "theModel = BertModel.from_pretrained('bert-base-uncased').to('cuda')\n",
        "\n",
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "max_input_length = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB8XNToIb7cU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sentence):\n",
        "    tokens = tokenizer.tokenize(sentence) \n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TliERKVJo1JB",
        "colab_type": "code",
        "outputId": "5184ff2d-60f3-4750-f6d9-11551db392da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "pip install torchtext"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.17.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.3.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2019.11.28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV1XJj8IbumB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import data\n",
        "\n",
        "TEXT = data.Field(batch_first = True, #requirement of bert\n",
        "                  use_vocab = False, #bert deals with the vocab\n",
        "                  tokenize = tokenize, #tokenize the word\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.float)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT7ib6ZFowMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "train, test = datasets.IMDB.splits(TEXT, LABEL) #test train split\n",
        "train, valid = train.split(random_state = random.seed(SEED))\n",
        "LABEL.build_vocab(train,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKQ4k4EYcxCN",
        "colab_type": "text"
      },
      "source": [
        "Building the NN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPH3dKPtc3Sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batchSize = 32 #batchsize \n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train, valid, test), \n",
        "    batch_size = batchSize, \n",
        "    device = 'cuda') #???"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_2j7Beo0Ft4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self,bert,hidden_dim,output_dim,n_layers,bidirectional,dropout):\n",
        "\n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert\n",
        "        \n",
        "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "        \n",
        "        self.rnn = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            embedded = theModel(text)[0]\n",
        "        \n",
        "        _, hidden = self.rnn(embedded)\n",
        "    \n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "                \n",
        "        #hidden = [batch size, hid dim]\n",
        "        \n",
        "        output = self.out(hidden)\n",
        "    \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOLaphNadkNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting an instance of the model and disabling paramaters to make training faster\n",
        "\n",
        "trained = NN(theModel,256,1,2,True,0.25)\n",
        "\n",
        "for name, param in trained.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6oukny_eP0H",
        "colab_type": "text"
      },
      "source": [
        "Running the NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOL5VmHfeV5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss().to('cuda') #setup loss criterion\n",
        "trained = trained.to('cuda')\n",
        "optimizer = optimizer.Adam(trained.parameters()) #Adam optimizer -> Used for everything:)\n",
        "numberOfRuns = 6\n",
        "bestLoss = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftEY_p6jfBls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to test error & findout test Accuracy\n",
        "def TestAccuracy(predicted, label):\n",
        "    prediction = torch.round(torch.sigmoid(predicted)) #round predicted value to integer\n",
        "    correctNum = (predicted == label).float() #convert into float for division \n",
        "    predictionAccuracy = correctNum.sum() / len(correctNum) #divide correct by total\n",
        "    return predictionAccuracy\n",
        "\n",
        "def evaluateModel(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    trained.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = trained(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = TestAccuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7CnDCuJfBnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to Train #todo\n",
        "def trainModel(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    trained.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = trained(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = TestAccuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVdN6hE5nAsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAkuG1bTehVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Running the previous 2 functions #todo\n",
        "#~30mins for 1 epoch\n",
        "for epoch in range(numberOfRuns):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = trainModel(trained, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluateModel(trained, valid_iterator, criterion)\n",
        "        \n",
        "    end_time = time.time()\n",
        "        \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        \n",
        "    if valid_loss < bestLoss:\n",
        "        bestLoss = valid_loss\n",
        "        torch.save(model.state_dict(), 'bestModel.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "bestTrained.load_state_dict(torch.load('bestModel.pt'))\n",
        "test_loss, test_acc = evaluate(bestTrained, test_iterator, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjZh8-56fC2I",
        "colab_type": "text"
      },
      "source": [
        "Predicting the Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy_d2DW7ehTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analysis(sentence):\n",
        "    trained.eval()\n",
        "    sentence2 = tokenizer.tokenize(sentence)\n",
        "    sentence3 = [init_token_idx] + tokenizer.convert_tokens_to_ids(sentence2) + [eos_token_idx]\n",
        "    sentence4 = torch.LongTensor(sentence3).to('cuda')\n",
        "    sentence5 = sentence4.unsqueeze(0)\n",
        "    prediction = torch.sigmoid(trained(sentence5))\n",
        "    result = round(prediction.item(), 4)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AObqNM7paTUX",
        "colab_type": "code",
        "outputId": "de21a038-be61-44cc-8cc3-a2030aba7a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "path = F\"/content/gdrive/My Drive/KWHS2019/Colab_Models/BERTModel.pt\" \n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-aa306c9ae673>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mF\"/content/gdrive/My Drive/KWHS2019/Colab_Models/BERTModel.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v4vqcs01mHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analysis(\"This film is terrible\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKklJgxoHvPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analysis(\"This film is Great\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WFkqyyiKLNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = 'BERTModel.pt'\n",
        "path = F\"/content/gdrive/My Drive/KWHS2019/Colab_Models/{model_save_name}\" \n",
        "torch.save(trained.state_dict(), path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxfAGCHER5Du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}